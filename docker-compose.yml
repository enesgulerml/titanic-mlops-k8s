version: '3.8'

services:
  api:
    image: ${FULL_IMAGE_NAME:-titanic-api:local}
    container_name: titanic-api
    build:
      context: .
      dockerfile: Dockerfile
    command: uvicorn src.api.app:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - redis
      - mlflow
    restart: always

  ui:
    image: ${FULL_IMAGE_NAME:-titanic-ui:local}
    container_name: titanic-ui
    build:
      context: .
      dockerfile: Dockerfile
    command: streamlit run src/ui/dashboard.py --server.port 8501 --server.address 0.0.0.0
    ports:
      - "80:8501"
    environment:
      - API_URL=http://api:8000
    depends_on:
      - api
    restart: always

  redis:
    image: redis:alpine
    container_name: titanic-redis
    ports:
      - "6379:6379"
    restart: always

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.11.1
    container_name: titanic-mlflow
    ports:
      - "5000:5000"
    command: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0
    volumes:
      - ./mlflow_data:/mlflow
    restart: always